#@meta {desc: 'training (only) configuration (see README.md)', date: '2024-02-01'}

[amr_trainer_default]
trainer_type = xfm
model_name = zsl_${amr_default:parse_model}

[amr_default]
parse_model = xfm_bart_base

[amr_parse_xfm_trainer]
# uncomment the next two lines to train from the last amrlib checkpoint (error
# loading checkpoint tokenizer if commented out)
pretrained_path_or_model = facebook/bart-base
training_config_file = resource(zensols.amr): resources/train/model_parse_xfm_bart_base.json
training_config_overrides = dict: {
  'hf_args': {
    'per_device_train_batch_size': 12,
    'num_train_epochs': 22}}
