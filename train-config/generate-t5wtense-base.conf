#@meta {desc: 'training (only) configuration (see README.md)', date: '2024-02-01'}

[amr_trainer_default]
trainer_type = t5wtense
model_name = zsl_${trainer_type}_base
trainer_is_generator = True

[amr_default]
parse_model = t5

[amr_generate_t5wtense_trainer]
# uncomment the next two lines to train from the last amrlib checkpoint
pretrained_path_or_model = t5-base
training_config_file = resource(zensols.amr): resources/model/model_generate_xfm_t5_base_wTT.json
training_config_overrides = dict: {
  'hf_args': {
    'num_train_epochs': 12,
    'per_device_train_batch_size': 14}}
# use scipy model for the Bio AMR corpus
annotate_model = en_core_sci_md
