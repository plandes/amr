## makefile automates the build and deployment for python projects


## Build system
#
PROJ_TYPE =		python
PROJ_MODULES =		git python-resources python-cli python-doc python-doc-deploy
INFO_TARGETS +=		appinfo
PY_DEP_POST_DEPS +=	modeldeps
MODEL_CONF_DIR = 	models
MODEL_NAME = 		little-prince
CLEAN_DEPS +=		cleanexample
CLEAN_ALL_DEPS +=	cleanalldep
ENTRY_BIN =		./amr


## Project
#
# text to parse for run examples
TEST_TEXT = 		"Barack Obama is an American politician who served as the 44th president of the United States from 2009 to 2017. A member of the Democratic Party, he was the first African-American president of the United States."


## Includes
#
include ./zenbuild/main.mk


## Targets
#
.PHONY:			appinfo
appinfo:
			@echo "app-resources-dir: $(RESOURCES_DIR)"

# download [spacy models](https://spacy.io/models/en)
.PHONY:			modeldeps
modeldeps:
			$(PIP_BIN) install $(PIP_ARGS) -r $(PY_SRC)/requirements-model.txt

# test parsing text
.PHONY:			testparse
testparse:
			$(ENTRY_BIN) parse $(TEST_TEXT)

# test plotting text
.PHONY:			testplot
testplot:
			$(ENTRY_BIN) plot $(TEST_TEXT)

# run all examples
.PHONY:			testexample
testexample:
			( cd example ; for i in *.py ; do ./$$i ; done )

# unit and integration testing
.PHONY:			testall
testall:		test testparse testplot testexample

# generate AMR plots of the little prince and the biomedical corpora
.PHONY:			renderexamples
renderexamples:
			$(ENTRY_BIN) plotfile corpus/amr-bank-struct-v3.0.txt
			$(ENTRY_BIN) plotfile corpus/amr-release-bio-v3.0.txt

# train on the little prince corpus
.PHONY:			trainlp
trainlp:
			CUDA_VISIBLE_DEVICES=0 TOKENIZERS_PARALLELISM=false \
				$(ENTRY_BIN) train \
				-c $(MODEL_CONF_DIR)/$(MODEL_NAME).conf

# train on the bio medical corpus
.PHONY:			trainbio
trainbio:
			make MODEL_NAME=bio-xfm-base trainlp

# evaluate the little prince corpus
.PHONY:			evallp
evallp:
			nohup $(ENTRY_BIN) eval -c $(MODEL_CONF_DIR)/$(MODEL_NAME).conf > eval-$(MODEL_NAME).log 2>&1 &

# evaluate the bio medical corpus
.PHONY:			evalbioondefault
evalbioondefault:
			nohup $(ENTRY_BIN) eval -c $(MODEL_CONF_DIR)/bio.conf \
				> eval-bio-on-default.log 2>&1 &

.PHONY:			evalbioonbio
evalbioonbio:
			nohup $(ENTRY_BIN) eval -c $(MODEL_CONF_DIR)/bio.conf \
				--override amr_parser.alternate_path='$${amr_trainer_default:model_dir}',amr_trainer_default.eval_model_name='$${model_name}' \
				> eval-bio-on-bio.log 2>&1 &

# stop any training
.PHONY:			stop
stop:
			ps -eaf | grep python | grep $(ENTRY_BIN) | awk '{print $2}' | xargs kill

# additional clean up using the harness/API (data dir)
.PHONY:			cleanalldep
cleanalldep:
			$(ENTRY_BIN) clean --clevel 1

# remove the ./data and ./corpus dir
.PHONY:			vaporize
vaporize:
			$(ENTRY_BIN) clean --clevel 2

# clean data generated by examples
.PHONY:			cleanexample
cleanexample:
			$(ENTRY_BIN) clean --clevel 0
			rm -fr example/data
