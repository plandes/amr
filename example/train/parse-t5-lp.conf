#@meta {desc: 'training (only) configuration', date: '2024-02-01'}

[import]
sections = list: lp_imp

[lp_imp]
config_file = example/train/lp.conf

[amr_trainer_default]
trainer_type = parse_t5
model_name = lp_parse_${amr_default:parse_model}

[amr_default]
parse_model = t5

[amr_t5_trainer]
# training the T5 has not been tested on training from a checkpoint; changes
# will need to be made given T5 uses the amrlib_meta.json insted of
# model_parse_xfm_bart_base.json
pretrained_path_or_model = t5-base
training_config_file = resource(zensols.amr): resources/train/model_parse_xfm_t5_base.json

training_config_overrides = dict: {
  'hf_args': {'num_train_epochs': 1}}
#training_config_overrides = dict: {'hf_args': {'fp16': False}}
